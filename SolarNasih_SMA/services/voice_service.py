from typing import Dict, Any, Optional, Tuple
import speech_recognition as sr
from gtts import gTTS
import tempfile
import os
from io import BytesIO
from fastapi import UploadFile
import logging
import subprocess
import shutil

logger = logging.getLogger(__name__)

class VoiceService:
    """
    Service de traitement vocal pour Solar Nasih
    """
    
    def __init__(self):
        self.recognizer = sr.Recognizer()
        self.supported_languages = {
            'fr': 'fr-FR',
            'en': 'en-US',
            'es': 'es-ES',
            'de': 'de-DE',
            'it': 'it-IT'
        }
        
        # Configuration du recognizer
        self.recognizer.energy_threshold = 300
        self.recognizer.dynamic_energy_threshold = True
        self.recognizer.pause_threshold = 0.8
        self.recognizer.operation_timeout = 30
    
    async def transcribe_audio(
        self, 
        audio_file: UploadFile, 
        language: str = 'fr'
    ) -> Dict[str, Any]:
        """
        Transcrit un fichier audio en texte
        
        Args:
            audio_file: Fichier audio uploadÃ©
            language: Langue de transcription
            
        Returns:
            RÃ©sultat de transcription avec confiance
        """
        
        try:
            # Lecture du fichier audio
            audio_data = await audio_file.read()
            
            # DÃ©terminer l'extension basÃ©e sur le nom du fichier
            filename = audio_file.filename or "audio"
            if filename.endswith('.webm'):
                suffix = '.webm'
            elif filename.endswith('.wav'):
                suffix = '.wav'
            elif filename.endswith('.mp3'):
                suffix = '.mp3'
            else:
                suffix = '.webm'  # Par dÃ©faut
            
            # Sauvegarde temporaire avec la bonne extension
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as temp_file:
                temp_file.write(audio_data)
                temp_file_path = temp_file.name
            
            logger.info(f"ðŸ“ Fichier audio temporaire crÃ©Ã©: {temp_file_path}")
            logger.info(f"ðŸ“ Taille du fichier: {len(audio_data)} bytes")
            
            try:
                # VÃ©rifier si le fichier est supportÃ© par speech_recognition
                if suffix == '.webm':
                    logger.warning("âš ï¸ Format WebM dÃ©tectÃ© - tentative de conversion...")
                    
                    # Essayer d'abord avec ffmpeg si disponible (global ou local)
                    ffmpeg_path = shutil.which('ffmpeg') or 'ffmpeg.exe'
                    if os.path.exists(ffmpeg_path) or shutil.which('ffmpeg') is not None:
                        wav_file_path = temp_file_path.replace('.webm', '.wav')
                        try:
                            # Conversion WebM vers WAV
                            cmd = [
                                ffmpeg_path, '-i', temp_file_path,
                                '-acodec', 'pcm_s16le',
                                '-ar', '16000',
                                '-ac', '1',
                                wav_file_path,
                                '-y'  # Ã‰craser le fichier s'il existe
                            ]
                            
                            result = subprocess.run(cmd, capture_output=True, text=True)
                            
                            if result.returncode == 0:
                                logger.info(f"âœ… Conversion WebM vers WAV rÃ©ussie: {wav_file_path}")
                                temp_file_path = wav_file_path  # Utiliser le fichier WAV converti
                            else:
                                logger.error(f"âŒ Erreur conversion ffmpeg: {result.stderr}")
                                raise Exception(f"Conversion Ã©chouÃ©e: {result.stderr}")
                                
                        except Exception as conv_error:
                            logger.error(f"âŒ Erreur lors de la conversion: {conv_error}")
                            # Continuer avec le fichier WebM original
                            pass
                    else:
                        logger.warning("âš ï¸ ffmpeg non disponible - tentative avec le fichier WebM original")
                        # Pour l'instant, retourner un message d'aide
                        return {
                            'transcribed_text': "Pour une meilleure reconnaissance vocale, veuillez installer ffmpeg ou utiliser un navigateur qui enregistre en WAV.",
                            'confidence': 0.0,
                            'detected_language': language,
                            'duration_seconds': 0,
                            'success': False,
                            'error': 'ffmpeg non disponible',
                            'help': 'Installez ffmpeg ou utilisez un navigateur compatible WAV'
                        }
                
                # Transcription avec speech_recognition
                logger.info(f"ðŸŽµ Ouverture du fichier audio: {temp_file_path}")
                with sr.AudioFile(temp_file_path) as source:
                    logger.info(f"ðŸ“Š PropriÃ©tÃ©s audio: {source.DURATION}s, {source.SAMPLE_RATE}Hz, {source.SAMPLE_WIDTH} bytes")
                    
                    # Ajustement du bruit ambiant
                    self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                    
                    # Enregistrement de l'audio
                    audio = self.recognizer.record(source)
                    logger.info(f"ðŸŽ¤ Audio enregistrÃ© pour transcription")
                
                # Transcription
                lang_code = self.supported_languages.get(language, 'fr-FR')
                
                try:
                    logger.info(f"ðŸŽ¤ Tentative de transcription avec Google Speech (langue: {lang_code})")
                    # Essai avec Google Speech Recognition
                    text = self.recognizer.recognize_google(audio, language=lang_code)
                    confidence = 0.8  # Google ne retourne pas de score de confiance
                    logger.info(f"âœ… Transcription Google rÃ©ussie: '{text}'")
                    
                except sr.UnknownValueError as e:
                    logger.warning(f"âš ï¸ Google Speech n'a pas reconnu l'audio: {e}")
                    # Essai avec reconnaissance offline si disponible
                    try:
                        logger.info("ðŸ”„ Tentative avec Sphinx (reconnaissance offline)")
                        text = self.recognizer.recognize_sphinx(audio)
                        confidence = 0.6
                        logger.info(f"âœ… Transcription Sphinx rÃ©ussie: '{text}'")
                    except Exception as sphinx_error:
                        logger.error(f"âŒ Sphinx a aussi Ã©chouÃ©: {sphinx_error}")
                        text = ""
                        confidence = 0.0
                
                except sr.RequestError as e:
                    logger.error(f"âŒ Erreur API Google Speech: {e}")
                    text = ""
                    confidence = 0.0
                
                return {
                    'transcribed_text': text,
                    'confidence': confidence,
                    'detected_language': language,
                    'duration_seconds': len(audio_data) / (16000 * 2),  # Estimation
                    'success': bool(text)
                }
                
            finally:
                # Nettoyage des fichiers temporaires
                if os.path.exists(temp_file_path):
                    os.unlink(temp_file_path)
                
                # Nettoyer aussi le fichier WAV converti s'il existe
                if suffix == '.webm' and 'wav_file_path' in locals():
                    if os.path.exists(wav_file_path):
                        os.unlink(wav_file_path)
                    
        except Exception as e:
            logger.error(f"Erreur lors de la transcription: {e}")
            return {
                'transcribed_text': "",
                'confidence': 0.0,
                'detected_language': language,
                'duration_seconds': 0,
                'success': False,
                'error': str(e)
            }
    
    async def generate_speech(
        self, 
        text: str, 
        language: str = 'fr',
        slow: bool = False
    ) -> Tuple[bytes, str]:
        """
        GÃ©nÃ¨re un fichier audio Ã  partir de texte
        
        Args:
            text: Texte Ã  synthÃ©tiser
            language: Langue de synthÃ¨se
            slow: Vitesse de lecture lente
            
        Returns:
            Tuple (donnÃ©es audio, nom fichier)
        """
        
        try:
            # Limitation de la longueur du texte
            if len(text) > 1000:
                text = text[:1000] + "..."
            
            # Configuration gTTS
            lang_code = language if language in ['fr', 'en', 'es', 'de', 'it'] else 'fr'
            
            # GÃ©nÃ©ration avec gTTS
            tts = gTTS(text=text, lang=lang_code, slow=slow)
            
            # Sauvegarde en mÃ©moire
            audio_buffer = BytesIO()
            tts.write_to_fp(audio_buffer)
            audio_buffer.seek(0)
            
            # GÃ©nÃ©ration du nom de fichier
            filename = f"response_{hash(text)}.mp3"
            
            return audio_buffer.getvalue(), filename
            
        except Exception as e:
            logger.error(f"Erreur lors de la gÃ©nÃ©ration audio: {e}")
            # Retour d'un fichier vide en cas d'erreur
            return b'', 'error.mp3'
    
    def detect_language_from_audio(self, audio_data: bytes) -> str:
        """
        DÃ©tecte la langue parlÃ©e dans l'audio
        
        Args:
            audio_data: DonnÃ©es audio
            
        Returns:
            Code langue dÃ©tectÃ©
        """
        
        try:
            # Sauvegarde temporaire
            with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
                temp_file.write(audio_data)
                temp_file_path = temp_file.name
            
            try:
                with sr.AudioFile(temp_file_path) as source:
                    audio = self.recognizer.record(source)
                
                # Essai de transcription dans diffÃ©rentes langues
                languages_to_try = ['fr-FR', 'en-US', 'es-ES', 'de-DE', 'it-IT']
                
                for lang in languages_to_try:
                    try:
                        text = self.recognizer.recognize_google(audio, language=lang)
                        if text:
                            return lang[:2]  # Retourne le code Ã  2 lettres
                    except:
                        continue
                
                return 'fr'  # DÃ©faut en franÃ§ais
                
            finally:
                if os.path.exists(temp_file_path):
                    os.unlink(temp_file_path)
                    
        except Exception as e:
            logger.error(f"Erreur dÃ©tection langue: {e}")
            return 'fr'
    
    def validate_audio_file(self, audio_file: UploadFile) -> Dict[str, Any]:
        """
        Valide un fichier audio uploadÃ©
        
        Args:
            audio_file: Fichier Ã  valider
            
        Returns:
            RÃ©sultat de validation
        """
        
        result = {
            'valid': True,
            'errors': [],
            'warnings': []
        }
        
        # VÃ©rification du type de fichier
        allowed_types = [
            'audio/wav', 'audio/wave', 'audio/x-wav',
            'audio/mpeg', 'audio/mp3',
            'audio/ogg', 'audio/webm',
            'audio/flac', 'audio/x-flac'
        ]
        
        if audio_file.content_type not in allowed_types:
            result['valid'] = False
            result['errors'].append(f"Type de fichier non supportÃ©: {audio_file.content_type}")
        
        # VÃ©rification de l'extension
        allowed_extensions = ['.wav', '.mp3', '.ogg', '.webm', '.flac']
        if not any(audio_file.filename.lower().endswith(ext) for ext in allowed_extensions):
            result['warnings'].append("Extension de fichier inhabituelle")
        
        # VÃ©rification de la taille (max 25MB)
        if hasattr(audio_file, 'size') and audio_file.size > 25 * 1024 * 1024:
            result['valid'] = False
            result['errors'].append("Fichier trop volumineux (max 25MB)")
        
        return result
    
    def optimize_audio_for_recognition(self, audio_data: bytes) -> bytes:
        """
        Optimise l'audio pour amÃ©liorer la reconnaissance
        
        Args:
            audio_data: DonnÃ©es audio originales
            
        Returns:
            DonnÃ©es audio optimisÃ©es
        """
        
        try:
            # En production, utiliser des bibliothÃ¨ques comme pydub
            # pour normaliser le volume, rÃ©duire le bruit, etc.
            
            # Pour cette implÃ©mentation, on retourne l'audio tel quel
            return audio_data
            
        except Exception as e:
            logger.error(f"Erreur optimisation audio: {e}")
            return audio_data
    
    def get_voice_commands_help(self, language: str = 'fr') -> Dict[str, str]:
        """
        Retourne l'aide sur les commandes vocales
        
        Args:
            language: Langue pour l'aide
            
        Returns:
            Dictionnaire des commandes et descriptions
        """
        
        if language == 'fr':
            return {
                "calcule": "Demande de simulation Ã©nergÃ©tique",
                "prix": "Information sur les coÃ»ts",
                "installation": "Conseils techniques d'installation",
                "aide": "Informations sur les aides financiÃ¨res",
                "rÃ©glementation": "Questions rÃ©glementaires",
                "formation": "Informations sur les formations",
                "document": "GÃ©nÃ©ration de documents"
            }
        
        elif language == 'en':
            return {
                "calculate": "Energy simulation request",
                "price": "Cost information",
                "installation": "Technical installation advice",
                "help": "Financial aid information",
                "regulation": "Regulatory questions",
                "training": "Training information",
                "document": "Document generation"
            }
        
        else:
            return self.get_voice_commands_help('fr')  # DÃ©faut en franÃ§ais
    
    def extract_voice_intent(self, transcribed_text: str) -> Dict[str, Any]:
        """
        Extrait l'intention Ã  partir du texte transcrit
        
        Args:
            transcribed_text: Texte transcrit
            
        Returns:
            Intention dÃ©tectÃ©e avec mÃ©tadonnÃ©es
        """
        
        text_lower = transcribed_text.lower()
        
        # Patterns d'intention pour la voix
        intentions = {
            'simulation': ['calcule', 'simule', 'estime', 'combien produit'],
            'prix': ['prix', 'coÃ»t', 'coÃ»te', 'tarif', 'budget'],
            'technique': ['comment installer', 'installation', 'technique', 'problÃ¨me'],
            'aide': ['aide', 'subvention', 'prime', 'financement'],
            'info': ['qu\'est-ce que', 'explique', 'dÃ©finition', 'c\'est quoi']
        }
        
        detected_intent = 'info'  # DÃ©faut
        confidence = 0.5
        
        for intent, patterns in intentions.items():
            matches = sum(1 for pattern in patterns if pattern in text_lower)
            if matches > 0:
                detected_intent = intent
                confidence = min(0.8, 0.4 + matches * 0.2)
                break
        
        return {
            'intent': detected_intent,
            'confidence': confidence,
            'keywords': [word for word in text_lower.split() if len(word) > 3],
            'original_text': transcribed_text
        }