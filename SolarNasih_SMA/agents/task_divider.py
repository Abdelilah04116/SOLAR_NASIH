from typing import Dict, Any, List
from langchain.tools import Tool
from agents.base_agent import BaseAgent
from models.schemas import AgentType, AgentState
from services.tavily_service import TavilyService
from services.gemini_service import GeminiService
from services.rag_service import RAGService
import re
import logging

logger = logging.getLogger(__name__)

class TaskDividerAgent(BaseAgent):
    """
    Agent Diviseur de T√¢ches - Route les requ√™tes vers les agents appropri√©s
    """
    
    def __init__(self):
        super().__init__(
            agent_type=AgentType.TASK_DIVIDER,
            description="Agent qui analyse et route les requ√™tes vers les agents sp√©cialis√©s"
        )
        self.tavily_service = TavilyService()
        self.gemini_service = GeminiService()
        self.rag_service = RAGService()  # Service RAG pour appels directs
        
        # Patterns de routage COMPLETS pour tous les agents
        self.route_patterns = {
            AgentType.RAG_SYSTEM: [
                r"qu'est-ce que", r"d√©finition", r"expliquer", r"comment fonctionne",
                r"principe", r"th√©orie", r"concept", r"information sur", r"c'est quoi"
            ],
            AgentType.TECHNICAL_ADVISOR: [
                r"installation", r"technique", r"c√¢blage", r"onduleur", r"panneau",
                r"dimensionnement", r"probl√®me technique", r"maintenance", r"diagnostic",
                r"sch√©ma", r"protection", r"fusible", r"disjoncteur"
            ],
            AgentType.ENERGY_SIMULATOR: [
                r"simulation", r"calculer", r"estimation", r"production", r"√©conomie",
                r"rentabilit√©", r"amortissement", r"rendement", r"kwh", r"kwc",
                r"retour sur investissement", r"roi", r"payback"
            ],
            AgentType.REGULATORY_ASSISTANT: [
                r"r√©glementation", r"loi", r"norme", r"obligation", r"conformit√©",
                r"permis", r"autorisation", r"l√©gislation", r"code", r"arr√™t√©",
                r"nf c 15-100", r"consuel", r"enedis"
            ],
            AgentType.COMMERCIAL_ASSISTANT: [
                r"prix", r"co√ªt", r"devis", r"tarif", r"financement", r"cr√©dit",
                r"subvention", r"aide", r"pr√™t", r"budget", r"offre", r"taux"
            ],
            AgentType.CERTIFICATION_ASSISTANT: [
                r"certification", r"rge", r"qualibat", r"label", r"formation",
                r"qualification", r"agr√©ment", r"habilitation", r"recyclage"
            ],
            AgentType.DOCUMENT_GENERATOR: [
                r"g√©n√©rer", r"cr√©er document", r"rapport", r"contrat", r"facture",
                r"attestation", r"certificat", r"devis", r"devis d√©taill√©", r"prix", 
                r"estimation", r"tarif", r"pdf", r"document", r"g√©n√®re", r"cr√©er"
            ],
            AgentType.EDUCATIONAL_AGENT: [
                r"apprendre", r"cours", r"formation", r"tutoriel", r"guide",
                r"√©tape par √©tape", r"explication simple", r"comprendre",
                r"niveau d√©butant", r"quiz", r"exercice"
            ],
            AgentType.VOICE_PROCESSOR: [
                r"vocal", r"audio", r"parler", r"√©couter", r"micro",
                r"transcription", r"synth√®se vocale"
            ],
            AgentType.MULTILINGUAL_DETECTOR: [
                r"english", r"espa√±ol", r"deutsch", r"italiano",
                r"translate", r"traduction", r"langue", r"the", r"and", r"is", r"are",
                r"ŸÉŸäŸÅ", r"ŸÑŸÖÿßÿ∞ÿß", r"ÿ£ŸäŸÜ", r"ŸÖŸÜ", r"ŸÖÿßÿ∞ÿß", r"ŸÖÿ™Ÿâ", r"ŸÉŸäŸÅÿßÿ¥", r"ÿπŸÑÿßÿ¥",
                r"‚µé‚¥∞‚µè", r"‚µé‚¥∞‚µè‚µâ", r"‚µé‚¥∞‚µè‚µâ‚µé"
            ],
            AgentType.DOCUMENT_INDEXER: [
                r"indexer", r"ajouter document", r"upload", r"int√©grer",
                r"base documentaire", r"catalogue"
            ]
        }

    
    def _init_tools(self) -> List[Tool]:
        """Initialise les outils du diviseur de t√¢ches"""
        return [
            Tool(
                name="analyze_intent",
                description="Analyse l'intention de l'utilisateur",
                func=self._analyze_intent
            ),
            Tool(
                name="route_to_agent",
                description="Route vers l'agent appropri√©",
                func=self._route_to_agent
            ),
            Tool(
                name="search_context",
                description="Recherche du contexte suppl√©mentaire",
                func=self._search_context
            )
        ]
    
    def _get_system_prompt(self) -> str:
        """Prompt syst√®me pour le diviseur de t√¢ches"""
        return """
        Tu es l'Agent Diviseur de T√¢ches du syst√®me Solar Nasih.
        
        Ton r√¥le est d'analyser les requ√™tes utilisateur et de les router vers l'agent appropri√© :
        
        1. **RAG_SYSTEM** : Questions informatives, d√©finitions, explications g√©n√©rales
        2. **TECHNICAL_ADVISOR** : Questions techniques, installation, maintenance
        3. **ENERGY_SIMULATOR** : Simulations, calculs, estimations √©nerg√©tiques
        4. **REGULATORY_ASSISTANT** : R√©glementation, normes, obligations l√©gales
        5. **COMMERCIAL_ASSISTANT** : Prix, devis, financement, aides
        6. **CERTIFICATION_ASSISTANT** : Certifications, formations, qualifications
        7. **DOCUMENT_GENERATOR** : G√©n√©ration de documents, rapports
        8. **EDUCATIONAL_AGENT** : Apprentissage, formation, tutoriels
        
        Analyse la requ√™te et d√©termine l'agent le plus appropri√©.
        Si plusieurs agents peuvent traiter la requ√™te, choisis le plus sp√©cialis√©.
        
        R√©ponds en fran√ßais et sois pr√©cis dans ton analyse.
        """
    
    def _analyze_intent(self, query: str) -> str:
        """Analyse l'intention de l'utilisateur"""
        query_lower = query.lower()
        
        # D√©tection des intentions principales
        intentions = []
        
        if any(word in query_lower for word in ["simulation", "calcul", "estimation"]):
            intentions.append("simulation_energetique")
        
        if any(word in query_lower for word in ["installation", "technique", "c√¢blage"]):
            intentions.append("conseil_technique")
        
        if any(word in query_lower for word in ["prix", "co√ªt", "financement"]):
            intentions.append("assistance_commerciale")
        
        if any(word in query_lower for word in ["r√©glementation", "norme", "loi"]):
            intentions.append("assistance_reglementaire")
        
        if any(word in query_lower for word in ["qu'est-ce que", "d√©finition", "expliquer"]):
            intentions.append("information_generale")
        
        return f"Intentions d√©tect√©es: {', '.join(intentions) if intentions else 'generale'}"
    
    def _route_to_agent(self, query: str) -> str:
        """Route la requ√™te vers l'agent appropri√©"""
        query_lower = query.lower()
        
        # Scores pour chaque agent
        agent_scores = {}
        
        for agent_type, patterns in self.route_patterns.items():
            score = 0
            for pattern in patterns:
                if re.search(pattern, query_lower):
                    score += 1
            agent_scores[agent_type] = score
        
        # Agent avec le score le plus √©lev√©
        best_agent = max(agent_scores, key=agent_scores.get)
        
        # Si aucun pattern ne correspond, utiliser le RAG par d√©faut
        if agent_scores[best_agent] == 0:
            best_agent = AgentType.RAG_SYSTEM
        
        return f"Agent recommand√©: {best_agent.value}"
    
    def _search_context(self, query: str) -> str:
        """Recherche du contexte suppl√©mentaire avec Tavily"""
        try:
            # Recherche avec Tavily pour enrichir le contexte
            results = self.tavily_service.search(f"√©nergie solaire {query}")
            
            if results:
                context = "Contexte suppl√©mentaire trouv√©:\n"
                for result in results[:2]:  # Limiter √† 2 r√©sultats
                    context += f"- {result.get('title', '')}: {result.get('content', '')[:100]}...\n"
                return context
            else:
                return "Aucun contexte suppl√©mentaire trouv√©"
                
        except Exception as e:
            return f"Erreur lors de la recherche de contexte: {str(e)}"
    
    async def route_request(self, state: AgentState) -> AgentType:
        """
        Route la requ√™te vers l'agent appropri√©
        """
        try:
            # Analyse de l'intention
            intent_analysis = self._analyze_intent(state.current_message)
            
            # Routage vers l'agent
            agent_recommendation = self._route_to_agent(state.current_message)
            
            # Extraction du type d'agent recommand√©
            agent_name = agent_recommendation.split(": ")[1]
            
            # Mise √† jour de l'√©tat
            state.user_intent = intent_analysis
            state.agent_route = AgentType(agent_name)
            
            return AgentType(agent_name)
            
        except Exception as e:
            # En cas d'erreur, router vers le RAG par d√©faut
            return AgentType.RAG_SYSTEM
    
    async def process(self, state: AgentState, agents_map: dict) -> dict:
        """M√©thode principale de traitement - analyse et route les requ√™tes"""
        try:
            # Stocker la question originale pour l'agent r√©sumeur
            self.current_user_question = state.current_message
            
            # 1. D√©tecter les agents pertinents
            detected_agents = self._detect_relevant_agents(state.current_message)
            
            if not detected_agents:
                logger.warning("Aucun agent d√©tect√©, utilisation du RAG par d√©faut")
                detected_agents = [AgentType.RAG_SYSTEM]
            
            # 2. V√©rifier d'abord le RAG si disponible
            rag_result = await self._check_rag_first(state.current_message)
            
            # 3. Obtenir les r√©ponses des agents
            agent_responses = await self._get_agent_responses(state, detected_agents, agents_map)
            
            # 4. Construire la r√©ponse finale
            final_response = await self._build_final_response(agent_responses, detected_agents)
            
            # 5. Calculer la confiance globale
            overall_confidence = self._calculate_overall_confidence(agent_responses)
            
            # 6. Collecter les sources
            sources = self._collect_sources(agent_responses)
        
            return {
                "response": final_response,
                "agent_used": "task_divider",
                "confidence": overall_confidence,
                "sources": sources,
                "agent_responses": agent_responses,
                "detected_agents": [agent.value for agent in detected_agents],
                "rag_result": rag_result
            }
            
        except Exception as e:
            logger.error(f"Erreur dans TaskDividerAgent: {e}")
            return {
                "response": f"Erreur lors du traitement: {str(e)}",
                "agent_used": "task_divider",
                "confidence": 0.0,
                "error": str(e),
                "sources": []
            }
    
    def _detect_relevant_agents(self, message: str) -> List[AgentType]:
        """D√©tecte les agents pertinents pour la requ√™te avec strat√©gie RAG-first"""
        query_lower = message.lower()
        detected_agents = []
        
        # üîç D√âTECTION AUTOMATIQUE DE LANGUE NON-FRAN√áAISE
        # D√©tecter si le message contient des caract√®res non-latins ou des mots-cl√©s anglais
        has_arabic = bool(re.search(r'[\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF]', message))
        has_tamazight = bool(re.search(r'[\u2D30-\u2D7F]', message))
        has_english = any(word in query_lower for word in ["the", "and", "is", "are", "was", "were", "with", "for", "but", "or"])
        
        # Si une langue non-fran√ßaise est d√©tect√©e, ajouter l'agent multilingue en priorit√©
        if has_arabic or has_tamazight or has_english:
            detected_agents.append(AgentType.MULTILINGUAL_DETECTOR)
            logger.info(f"üåê Langue non-fran√ßaise d√©tect√©e - Ajout de l'agent multilingue")
        
        # V√©rification des patterns pour les agents sp√©cialis√©s
        for agent_type, patterns in self.route_patterns.items():
            # Ignorer RAG_SYSTEM car il sera trait√© s√©par√©ment
            if agent_type == AgentType.RAG_SYSTEM:
                continue
                
            for pattern in patterns:
                if re.search(pattern, query_lower):
                    # √âviter les doublons
                    if agent_type not in detected_agents:
                        detected_agents.append(agent_type)
                    break
        
        # Ajout du RAG_SYSTEM en premier pour v√©rification prioritaire
        # Le RAG est toujours pertinent pour enrichir le contexte
        detected_agents.insert(0, AgentType.RAG_SYSTEM)
        
        # Si aucun agent sp√©cialis√© d√©tect√©, garder seulement RAG
        if len(detected_agents) == 1:
            logger.info("üîç Aucun agent sp√©cialis√© d√©tect√©, utilisation du RAG uniquement")
        
        logger.info(f"ü§ñ Agents d√©tect√©s: {[agent.value for agent in detected_agents]}")
        return detected_agents
    
    async def _get_agent_responses(self, state: AgentState, agents: List[AgentType], agents_map: dict) -> List[Dict[str, Any]]:
        """R√©cup√®re les r√©ponses des agents avec strat√©gie RAG-first"""
        responses = []
        
        # 1. üîç V√âRIFICATION RAG EN PREMIER - Appel direct au syst√®me RAG
        logger.info("üîç V√©rification RAG en premier...")
        rag_response = await self._check_rag_first(state.current_message)
        
        if rag_response and rag_response.get("success"):
            responses.append(rag_response)
            logger.info("‚úÖ RAG a trouv√© une r√©ponse pertinente")
        else:
            logger.info("‚ùå RAG n'a pas trouv√© de r√©ponse pertinente")
        
        # 2. üåê TRAITEMENT MULTILINGUE EN PRIORIT√â (si pr√©sent)
        detected_language = "fr"  # D√©faut fran√ßais
        multilingual_agent = None
        
        # Chercher l'agent multilingue dans la liste
        for agent_type in agents:
            if agent_type == AgentType.MULTILINGUAL_DETECTOR:
                multilingual_agent = agents_map.get(agent_type)
                break
        
        # Traiter l'agent multilingue en premier s'il est pr√©sent
        if multilingual_agent:
            try:
                logger.info("üåê Traitement de l'agent multilingue en priorit√©...")
                agent_state = self._prepare_agent_state(state, AgentType.MULTILINGUAL_DETECTOR)
                result = await multilingual_agent.process(agent_state)
                
                # Extraire la langue d√©tect√©e
                if "detected_language" in result:
                    detected_language = result["detected_language"]
                    logger.info(f"üåê Langue d√©tect√©e: {detected_language}")
                
                # Si l'agent multilingue a g√©n√©r√© une r√©ponse compl√®te, l'utiliser
                if result.get("response") and result.get("confidence", 0) > 0.7:
                    responses.append({
                        "agent_type": "multilingual_detector",
                        "response": result["response"],
                        "confidence": result.get("confidence", 0.8),
                        "sources": result.get("sources", []),
                        "success": True,
                        "detected_language": detected_language
                    })
                    logger.info("‚úÖ Agent multilingue a g√©n√©r√© une r√©ponse compl√®te")
                    return responses  # Retourner directement si r√©ponse compl√®te
                
                # Sinon, continuer avec les autres agents
                logger.info("üåê Agent multilingue a d√©tect√© la langue, traitement des autres agents...")
                
            except Exception as e:
                logger.error(f"‚ùå Erreur avec l'agent multilingue: {e}")
        
        # 3. ü§ñ APPEL DES AUTRES AGENTS SP√âCIALIS√âS
        for agent_type in agents:
            # Ignorer RAG_SYSTEM et MULTILINGUAL_DETECTOR car d√©j√† trait√©s
            if agent_type in [AgentType.RAG_SYSTEM, AgentType.MULTILINGUAL_DETECTOR]:
                continue
                
            agent = agents_map.get(agent_type)
            if agent:
                try:
                    # Pr√©paration de l'√©tat pour l'agent avec la langue d√©tect√©e
                    agent_state = self._prepare_agent_state(state, agent_type)
                    agent_state.detected_language = detected_language  # Passer la langue d√©tect√©e
                    
                    # Appel de l'agent
                    if agent_type == AgentType.TASK_DIVIDER:
                        result = await agent.process(agent_state, agents_map)
                    else:
                        result = await agent.process(agent_state)
                    
                    # Validation et nettoyage de la r√©ponse
                    cleaned_response = self._clean_agent_response(result, agent_type)
                    
                    if cleaned_response:
                        responses.append({
                            "agent_type": agent_type.value,
                            "response": cleaned_response,
                            "confidence": result.get("confidence", 0.7),
                            "sources": result.get("sources", []),
                            "success": True,
                            "detected_language": detected_language
                        })
                        logger.info(f"‚úÖ {agent_type.value} a g√©n√©r√© une r√©ponse")
                    else:
                        responses.append({
                            "agent_type": agent_type.value,
                            "response": f"L'agent {agent_type.value} n'a pas pu g√©n√©rer de r√©ponse.",
                            "confidence": 0.0,
                            "sources": [],
                            "success": False
                        })
                        logger.info(f"‚ùå {agent_type.value} n'a pas g√©n√©r√© de r√©ponse")
                        
                except Exception as e:
                    responses.append({
                        "agent_type": agent_type.value,
                        "response": f"Erreur lors de l'appel √† l'agent {agent_type.value}: {str(e)}",
                        "confidence": 0.0,
                        "sources": [],
                        "success": False,
                        "error": str(e)
                    })
                    logger.error(f"‚ùå Erreur avec {agent_type.value}: {e}")
            else:
                responses.append({
                    "agent_type": agent_type.value,
                    "response": f"Agent {agent_type.value} non disponible.",
                    "confidence": 0.0,
                    "sources": [],
                    "success": False
                })
                logger.warning(f"‚ö†Ô∏è {agent_type.value} non disponible")
        
        return responses
    
    async def _check_rag_first(self, query: str) -> Dict[str, Any]:
        """V√©rifie d'abord le syst√®me RAG pour une r√©ponse pertinente"""
        try:
            logger.info(f"üîç Appel direct au syst√®me RAG pour: {query[:50]}...")
            
            # Appel direct au service RAG
            rag_result = await self.rag_service.query(
                query=query,
                language="fr",
                max_results=3
            )
            
            # V√©rification de la qualit√© de la r√©ponse RAG
            if self._is_rag_response_quality(rag_result):
                return {
                    "agent_type": AgentType.RAG_SYSTEM.value,
                    "response": rag_result.get("answer", ""),
                    "confidence": rag_result.get("confidence", 0.8),
                    "sources": rag_result.get("sources", []),
                    "success": True,
                    "rag_score": rag_result.get("similarity_score", 0.0)
                }
            else:
                logger.info("‚ùå R√©ponse RAG de qualit√© insuffisante")
                return {
                    "agent_type": AgentType.RAG_SYSTEM.value,
                    "response": "Aucune information pertinente trouv√©e dans la base de connaissances.",
                    "confidence": 0.0,
                    "sources": [],
                    "success": False
                }
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'appel RAG: {e}")
            return {
                "agent_type": AgentType.RAG_SYSTEM.value,
                "response": f"Erreur lors de la consultation de la base de connaissances: {str(e)}",
                "confidence": 0.0,
                "sources": [],
                "success": False,
                "error": str(e)
            }
    
    def _is_rag_response_quality(self, rag_result: Dict[str, Any]) -> bool:
        """V√©rifie si la r√©ponse RAG est de qualit√© suffisante"""
        try:
            # V√©rification de la pr√©sence d'une r√©ponse
            answer = rag_result.get("answer", "")
            if not answer or len(answer.strip()) < 20:
                return False
            
            # V√©rification du score de similarit√©
            similarity_score = rag_result.get("similarity_score", 0.0)
            if similarity_score < 0.6:  # Seuil de qualit√©
                return False
            
            # V√©rification de la confiance
            confidence = rag_result.get("confidence", 0.0)
            if confidence < 0.5:  # Seuil de confiance
                return False
            
            # V√©rification des sources
            sources = rag_result.get("sources", [])
            if not sources:
                return False
            
            logger.info(f"‚úÖ Qualit√© RAG valid√©e - Score: {similarity_score:.2f}, Confiance: {confidence:.2f}")
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors de la v√©rification de qualit√© RAG: {e}")
            return False
    
    def _prepare_agent_state(self, state: AgentState, agent_type: AgentType) -> AgentState:
        """Pr√©pare l'√©tat sp√©cifique pour un agent"""
        # Cr√©ation d'un nouvel √©tat avec le bon agent_route
        agent_state = AgentState(
            current_message=state.current_message,
            detected_language=state.detected_language,
            user_intent=state.user_intent,
            agent_route=agent_type,
            context=state.context,
            response="",
            confidence=0.0,
            sources=[],
            processing_history=state.processing_history
        )
        return agent_state
    
    def _clean_agent_response(self, result: Dict[str, Any], agent_type: AgentType) -> str:
        """Nettoie et valide la r√©ponse d'un agent"""
        response = result.get("response", "")
        
        # V√©rification que la r√©ponse est valide
        if not response or not isinstance(response, str):
            return ""
        
        # Suppression des r√©ponses par d√©faut
        default_responses = [
            "solar nasih est un assistant",
            "je n'ai pas pu traiter",
            "aucune r√©ponse g√©n√©r√©e"
        ]
        
        response_lower = response.lower()
        for default in default_responses:
            if default in response_lower:
                return ""
        
        return response.strip()
    
    async def _build_final_response(self, agent_responses: List[Dict[str, Any]], detected_agents: List[AgentType]) -> str:
        """Construit la r√©ponse finale en format ChatGPT avec r√©sum√© automatique"""
        successful_responses = [r for r in agent_responses if r["success"] and r["response"]]
        
        if not successful_responses:
            return self._get_fallback_response()
        
        # üåê D√âTECTION DE LA LANGUE POUR TRADUCTION
        detected_language = "fr"  # D√©faut fran√ßais
        for response in successful_responses:
            if "detected_language" in response:
                detected_language = response["detected_language"]
                break
        
        # NOUVELLE APPROCHE : R√©ponse structur√©e style ChatGPT
        # 1. Combiner les meilleures r√©ponses
        combined_response = self._combine_agent_responses(successful_responses)
        
        # 2. Utiliser l'agent r√©sumeur pour formater la r√©ponse
        summarized_response = await self._summarize_with_agent(combined_response)
        
        # 3. Si l'agent r√©sumeur √©choue, utiliser le formatage automatique
        if not summarized_response or "Erreur" in summarized_response:
            summarized_response = self._format_chatgpt_style(combined_response)
        
        # üåê TRADUCTION AUTOMATIQUE SI N√âCESSAIRE
        if detected_language != "fr":
            try:
                from agents.multilingual_detector import MultilingualDetectorAgent
                multilingual_agent = MultilingualDetectorAgent()
                
                translation_result = await multilingual_agent.translate_text(
                    summarized_response, "fr", detected_language
                )
                
                if translation_result.get("confidence", 0) > 0.5:
                    summarized_response = translation_result["translated_text"]
                    logger.info(f"üåê R√©ponse traduite en {detected_language}")
                    
            except Exception as e:
                logger.error(f"üåê Erreur lors de la traduction: {e}")
        
        return summarized_response
    
    def _combine_agent_responses(self, responses: List[Dict[str, Any]]) -> str:
        """Combine les r√©ponses des agents en une seule r√©ponse"""
        if not responses:
            return ""
        
        # Prendre la meilleure r√©ponse (la plus pertinente)
        best_response = max(responses, key=lambda x: x.get("confidence", 0))
        
        # Si c'est une r√©ponse RAG de qualit√©, la prioriser
        rag_responses = [r for r in responses if r["agent_type"] == AgentType.RAG_SYSTEM.value]
        if rag_responses:
            best_rag = max(rag_responses, key=lambda x: x.get("rag_score", 0))
            if best_rag.get("rag_score", 0) > 0.6:
                return best_rag["response"]
        
        return best_response["response"]
    
    async def _summarize_with_agent(self, response: str) -> str:
        """Utilise l'agent r√©sumeur pour formater la r√©ponse"""
        try:
            from agents.response_summarizer import ResponseSummarizerAgent
            from models.schemas import AgentState
            
            # Cr√©er l'agent r√©sumeur
            summarizer = ResponseSummarizerAgent()
            
            # R√©cup√©rer la question originale depuis le contexte
            user_question = ""
            if hasattr(self, 'current_user_question'):
                user_question = self.current_user_question
            
            # Cr√©er l'√©tat avec la r√©ponse √† r√©sumer et la question originale
            state = AgentState(
                current_message=response,
                detected_language="fr",
                user_intent="",
                agent_route=AgentType.RESPONSE_SUMMARIZER,
                context={"user_question": user_question},
                response="",
                confidence=0.0,
                sources=[],
                processing_history=[]
            )
            
            # Traiter avec l'agent r√©sumeur
            result = await summarizer.process(state)
            
            return result.get("response", response)
            
        except Exception as e:
            logger.error(f"Erreur avec l'agent r√©sumeur: {e}")
            return response
    
    def _format_chatgpt_style(self, response: str) -> str:
        """Formate la r√©ponse en style ChatGPT automatiquement"""
        try:
            # Nettoyer la r√©ponse
            cleaned_response = self._clean_response(response)
            
            # G√©n√©rer un r√©sum√© automatique
            summary = self._generate_auto_summary(cleaned_response)
            
            # Extraire les points cl√©s
            key_points = self._extract_key_points(cleaned_response)
            
            # Formater en style ChatGPT
            formatted_response = f"""**{summary}**

{key_points}

**D√©tails :**
{cleaned_response[:300]}{'...' if len(cleaned_response) > 300 else ''}"""
            
            return formatted_response
            
        except Exception as e:
            logger.error(f"Erreur formatage ChatGPT: {e}")
            return response
    
    def _clean_response(self, response: str) -> str:
        """Nettoie la r√©ponse des m√©tadonn√©es"""
        if not response:
            return ""
        
        # Supprimer les m√©tadonn√©es et √©mojis
        lines = response.split('\n')
        cleaned_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Ignorer les lignes avec m√©tadonn√©es
            if any(skip in line.lower() for skip in [
                "confiance:", "similarit√©:", "score:", "agent:", "base de connaissances",
                "üü¢", "üü°", "üî¥", "üìö", "ü§ñ", "üîç", "**analyse de votre demande**"
            ]):
                continue
            
            # Ignorer les lignes trop techniques ou verbeuses
            if any(verbose in line.lower() for verbose in [
                "calcul de production √©nerg√©tique:", "estimation des √©conomies annuelles:",
                "calcul du retour sur investissement:", "dimensionnement optimal:",
                "impact environnemental:", "pour calculer le roi", "m√©thode:", "facteurs:"
            ]):
                continue
            
            cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)
    
    def _generate_auto_summary(self, response: str) -> str:
        """G√©n√®re un r√©sum√© automatique"""
        try:
            # Extraire les informations principales
            lines = response.split('\n')
            summary_parts = []
            
            for line in lines[:3]:  # Prendre les 3 premi√®res lignes utiles
                if any(keyword in line.lower() for keyword in ['kwh', 'kwc', '‚Ç¨', 'ans', 'production', 'co√ªt', 'prix']):
                    summary_parts.append(line)
            
            if summary_parts:
                return summary_parts[0][:100] + "..."
            else:
                return "Informations sur l'√©nergie solaire disponibles."
                
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration r√©sum√© auto: {e}")
            return "R√©sum√© de la r√©ponse g√©n√©r√©."
    
    def _extract_key_points(self, response: str) -> str:
        """Extrait les points cl√©s d'une r√©ponse"""
        try:
            # Extraction automatique des points cl√©s
            lines = response.split('\n')
            key_points = []
            
            # Chercher les lignes avec des donn√©es importantes
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # D√©tecter les lignes avec des donn√©es chiffr√©es
                if any(keyword in line.lower() for keyword in ['kwh', 'kwc', '‚Ç¨', 'ans', 'production', 'co√ªt', 'prix', '√©conomie']):
                    key_points.append(line)
                elif len(line) > 10 and len(line) < 100 and not line.startswith('*'):
                    key_points.append(line)
            
            # Limiter √† 5 points maximum
            if len(key_points) > 5:
                key_points = key_points[:5]
            
            if key_points:
                return "**Points cl√©s :**\n" + "\n".join([f"‚Ä¢ {point}" for point in key_points])
            else:
                return "**Informations principales :**\n" + response[:200] + "..."
                
        except Exception as e:
            logger.error(f"Erreur extraction points cl√©s: {e}")
            return "**Informations :**\n" + response[:200] + "..."
    
    def _get_fallback_response(self) -> str:
        """G√©n√®re une r√©ponse de fallback avec Gemini"""
        try:
            # Utilisation de Gemini pour une r√©ponse de fallback
            fallback_prompt = """
            Tu es Solar Nasih, un assistant sp√©cialis√© en √©nergie solaire.
            L'utilisateur a pos√© une question mais les agents sp√©cialis√©s n'ont pas pu r√©pondre.
            G√©n√®re une r√©ponse utile et informative en fran√ßais, en restant dans le domaine de l'√©nergie solaire.
            """
            # Note: Cette m√©thode n√©cessiterait l'int√©gration avec Gemini
            return "Je n'ai pas pu traiter votre demande avec les agents sp√©cialis√©s, mais je reste √† votre disposition pour toute question sur l'√©nergie solaire."
        except:
            return "Solar Nasih est un assistant intelligent d√©di√© √† l'√©nergie solaire. Posez-moi vos questions sur l'installation, la r√©glementation, la simulation, la certification ou le financement."
    
    def _calculate_overall_confidence(self, agent_responses: List[Dict[str, Any]]) -> float:
        """Calcule la confiance globale bas√©e sur les r√©ponses des agents"""
        successful_responses = [r for r in agent_responses if r["success"]]
        
        if not successful_responses:
            return 0.3
        
        confidences = [r["confidence"] for r in successful_responses]
        return sum(confidences) / len(confidences)
    
    def _collect_sources(self, agent_responses: List[Dict[str, Any]]) -> List[str]:
        """Collecte toutes les sources des agents"""
        sources = set()
        for response in agent_responses:
            if response["success"]:
                sources.update(response.get("sources", []))
        return list(sources)
    
    def can_handle(self, user_input: str, context: Dict[str, Any] = None) -> float:
        """Le diviseur de t√¢ches peut toujours traiter les requ√™tes"""
        return 1.0