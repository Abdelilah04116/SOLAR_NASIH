from typing import Dict, Any, List
from langchain.tools import Tool
from agents.base_agent import BaseAgent
from models.schemas import AgentType
from services.gemini_service import GeminiService
import re
import logging

logger = logging.getLogger(__name__)

class ResponseSummarizerAgent(BaseAgent):
    """
    Agent R√©sumeur de R√©ponses - Transforme les r√©ponses des agents en format structur√©
    """
    
    def __init__(self):
        super().__init__(
            agent_type=AgentType.RESPONSE_SUMMARIZER,
            description="Agent qui r√©sume et structure les r√©ponses des autres agents"
        )
        self.gemini_service = GeminiService()
    
    def _init_tools(self) -> List[Tool]:
        """Initialise les outils du r√©sumeur"""
        return [
            Tool(
                name="summarize_response",
                description="R√©sume et structure une r√©ponse",
                func=self._summarize_response
            ),
            Tool(
                name="extract_key_points",
                description="Extrait les points cl√©s d'une r√©ponse",
                func=self._extract_key_points
            ),
            Tool(
                name="format_chatgpt_style",
                description="Formate la r√©ponse en style ChatGPT",
                func=self._format_chatgpt_style
            )
        ]
    
    def _get_system_prompt(self) -> str:
        """Prompt syst√®me pour le r√©sumeur de r√©ponses"""
        return """
        Tu es l'Agent Formateur de R√©ponses du syst√®me Solar Nasih.
        
        Ton r√¥le est de formater les r√©ponses des agents sp√©cialis√©s en style structur√© et professionnel, similaire √† ChatGPT.
        
        **IMPORTANT : Ne r√©sume PAS le contenu, formate-le seulement !**
        
        **Format de sortie souhait√© :**
        1. **Titre contextuel** (gras, bas√© sur la question)
        2. **Points cl√©s** (extraction des donn√©es importantes)
        3. **Contenu original** (le contenu complet des agents)
        
        **R√®gles de formatage :**
        - Garder TOUT le contenu original
        - Ajouter seulement un titre et des points cl√©s
        - Extraire les points cl√©s pour faciliter la lecture
        - Utiliser UN SEUL saut de ligne entre sections
        - √âviter les sauts de ligne multiples
        - Langage clair et professionnel
        
        **Exemple de format :**
        **R√©ponse √† votre question sur l'√©nergie solaire.**

        **Points cl√©s :**
        ‚Ä¢ [Extraction automatique des donn√©es importantes]

        **Contenu d√©taill√© :**
        [Contenu complet des agents sans modification]
        """
    
    def _summarize_response(self, response: str) -> str:
        """R√©sume une r√©ponse en format structur√©"""
        try:
            if not response or len(response.strip()) < 10:
                return "Aucune information disponible pour g√©n√©rer un r√©sum√©."
            
            # Utiliser Gemini pour g√©n√©rer le r√©sum√©
            llm = self.gemini_service.get_llm()
            
            prompt = f"""
            Tu es un expert en r√©sum√© de contenu technique sur l'√©nergie solaire.
            
            Voici une r√©ponse d'un agent sp√©cialis√© :
            {response}
            
            Transforme cette r√©ponse en format structur√© avec :
            1. **R√©sum√© en une phrase** (gras, maximum 150 mots)
            2. **Points cl√©s** (3-5 points maximum, liste √† puces)
            3. **D√©tails techniques** (paragraphe court si n√©cessaire)
            4. **Recommandations** (si applicable)
            
            Utilise un langage clair, professionnel et accessible.
            """
            
            result = llm.invoke(prompt)
            return result.content if hasattr(result, 'content') else str(result)
            
        except Exception as e:
            logger.error(f"Erreur lors du r√©sum√©: {e}")
            return self._fallback_summarize(response)
    
    def _extract_key_points(self, response: str) -> str:
        """Extrait les points cl√©s d'une r√©ponse SANS couper"""
        try:
            # Extraction automatique des points cl√©s
            lines = response.split('\n')
            key_points = []
            
            # Chercher les lignes avec des donn√©es importantes
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # D√©tecter les lignes avec des donn√©es chiffr√©es
                if any(keyword in line.lower() for keyword in ['kwh', 'kwc', '‚Ç¨', 'ans', 'production', 'co√ªt', 'prix', '√©conomie']):
                    key_points.append(line)
                elif len(line) > 10 and len(line) < 100 and not line.startswith('*'):
                    key_points.append(line)
            
            # Limiter √† 5 points maximum pour l'affichage
            if len(key_points) > 5:
                key_points = key_points[:5]
            
            if key_points:
                return "**Points cl√©s :**\n" + "\n".join([f"‚Ä¢ {point}" for point in key_points])
            else:
                return "**Informations principales :**\n" + "Contenu complet disponible ci-dessous"
                
        except Exception as e:
            logger.error(f"Erreur extraction points cl√©s: {e}")
            return "**Informations :**\n" + "Contenu complet disponible ci-dessous"
    
    def _format_chatgpt_style(self, response: str) -> str:
        """Formate la r√©ponse en style ChatGPT SANS couper"""
        try:
            # Nettoyer la r√©ponse
            cleaned_response = self._clean_response(response)
            
            # G√©n√©rer un r√©sum√© automatique
            summary = self._generate_auto_summary(cleaned_response)
            
            # Extraire les points cl√©s
            key_points = self._extract_key_points(cleaned_response)
            
            # Formater en style ChatGPT avec TOUT le contenu
            formatted_response = f"**{summary}**\n\n{key_points}\n\n**Contenu d√©taill√© :**\n{cleaned_response}"
            
            return formatted_response
            
        except Exception as e:
            logger.error(f"Erreur formatage ChatGPT: {e}")
            return response
    
    def _clean_response(self, response: str) -> str:
        """Nettoie la r√©ponse des m√©tadonn√©es SANS couper le contenu"""
        if not response:
            return ""
        
        # Supprimer les m√©tadonn√©es et √©mojis
        lines = response.split('\n')
        cleaned_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Ignorer SEULEMENT les lignes avec m√©tadonn√©es syst√®me
            if any(skip in line.lower() for skip in [
                "confiance:", "similarit√©:", "score:", "agent:", "base de connaissances",
                "üü¢", "üü°", "üî¥", "üìö", "ü§ñ", "üîç", "**analyse de votre demande**"
            ]):
                continue
            
            # NE PAS ignorer les lignes techniques - elles font partie du contenu
            cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)
    
    def _generate_auto_summary(self, response: str) -> str:
        """G√©n√®re un r√©sum√© automatique"""
        try:
            # Extraire les informations principales
            lines = response.split('\n')
            summary_parts = []
            
            for line in lines[:3]:  # Prendre les 3 premi√®res lignes utiles
                if any(keyword in line.lower() for keyword in ['kwh', 'kwc', '‚Ç¨', 'ans', 'production', 'co√ªt', 'prix']):
                    summary_parts.append(line)
            
            if summary_parts:
                return summary_parts[0][:100] + "..."
            else:
                return "Informations sur l'√©nergie solaire disponibles."
                
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration r√©sum√© auto: {e}")
            return "R√©sum√© de la r√©ponse g√©n√©r√©."
    
    def _fallback_summarize(self, response: str) -> str:
        """R√©sum√© de fallback si Gemini √©choue SANS couper"""
        try:
            # R√©sum√© simple bas√© sur les mots-cl√©s
            response_lower = response.lower()
            
            if 'kwh' in response_lower and 'kwc' in response_lower:
                return f"**Simulation √©nerg√©tique g√©n√©r√©e.**\n\n**Points cl√©s :**\n‚Ä¢ Donn√©es de production et consommation calcul√©es\n‚Ä¢ Estimation des √©conomies r√©alis√©es\n‚Ä¢ Analyse de rentabilit√© incluse\n\n**Contenu d√©taill√© :**\n{response}"
            
            elif '‚Ç¨' in response_lower or 'prix' in response_lower:
                return f"**Informations financi√®res fournies.**\n\n**Points cl√©s :**\n‚Ä¢ Estimation des co√ªts d'installation\n‚Ä¢ Calcul des aides disponibles\n‚Ä¢ Analyse de rentabilit√©\n\n**Contenu d√©taill√© :**\n{response}"
            
            else:
                return f"**R√©ponse technique g√©n√©r√©e.**\n\n**Points cl√©s :**\n‚Ä¢ Informations sp√©cialis√©es fournies\n‚Ä¢ Recommandations techniques incluses\n‚Ä¢ Donn√©es actualis√©es\n\n**Contenu d√©taill√© :**\n{response}"
                
        except Exception as e:
            logger.error(f"Erreur fallback: {e}")
            return response
    
    async def process(self, state) -> Dict[str, Any]:
        """M√©thode principale de traitement - formate et structure la r√©ponse"""
        try:
            original_response = state.current_message
            user_question = state.context.get("user_question", "")
            
            # V√©rifier si c'est une r√©ponse longue (quiz, documents, guides)
            is_long_response = (
                len(original_response) > 5000 or 
                "Question" in original_response and original_response.count("Question") > 10 or
                "‚ïê‚ïê‚ïê" in original_response or  # Documents avec s√©parateurs
                "MAINTENANCE" in original_response or  # Guides de maintenance
                "FORMATION" in original_response or    # Documents de formation
                "DEVIS" in original_response or        # Devis d√©taill√©s
                "CONTRAT" in original_response         # Contrats complets
            )
            
            if is_long_response:
                # Pour les r√©ponses longues, utiliser le formatage local SANS Gemini
                logger.info("Long response detected, using local formatting without Gemini")
                formatted_response = self._format_chatgpt_style_with_context(original_response, user_question)
            else:
                # Pour les r√©ponses courtes, utiliser Gemini
                formatted_response = self._summarize_response_with_context(original_response, user_question)
                
                # Si le formatage √©choue, utiliser le formatage automatique
                if "Aucune information disponible" in formatted_response:
                    formatted_response = self._format_chatgpt_style_with_context(original_response, user_question)
            
            return {
                "response": formatted_response,
                "original_response": original_response,
                "agent_used": "response_formatter",
                "confidence": 0.9,
                "sources": ["Solar Nasih Response Formatter"],
                "processing_info": {
                    "formatted": True,
                    "format": "chatgpt_style",
                    "word_count": len(formatted_response.split()),
                    "user_question": user_question,
                    "content_preserved": True,
                    "long_response": is_long_response
                }
            }
            
        except Exception as e:
            logger.error(f"Erreur dans l'agent formateur: {e}")
            return {
                "response": f"Erreur lors du formatage: {str(e)}",
                "original_response": state.current_message,
                "agent_used": "response_formatter",
                "confidence": 0.0,
                "error": str(e),
                "sources": ["Solar Nasih Response Formatter"]
            }
    
    def _summarize_response_with_context(self, response: str, user_question: str) -> str:
        """Formate une r√©ponse en tenant compte de la question de l'utilisateur"""
        try:
            if not response or len(response.strip()) < 10:
                return "Aucune information disponible."
            
            # Utiliser Gemini pour formater la r√©ponse avec contexte
            llm = self.gemini_service.get_llm()
            
            prompt = f"""
            Tu es un expert en formatage de contenu technique sur l'√©nergie solaire.
            
            Question de l'utilisateur : {user_question}
            
            R√©ponse d'un agent sp√©cialis√© :
            {response}
            
            **IMPORTANT : Ne r√©sume PAS le contenu, formate-le seulement !**
            **CRITIQUE : Garder TOUT le contenu original, ne rien couper !**
            
            Transforme cette r√©ponse en format structur√© :
            1. **Titre contextuel** (gras, bas√© sur la question) - maximum 100 mots
            2. **Points cl√©s** (extraction des donn√©es importantes) - 3-5 points maximum
            3. **Contenu d√©taill√©** (le contenu original COMPLET sans aucune modification)
            
            **R√®gles STRICTES :**
            - Garder TOUT le contenu original sans aucune coupure
            - Ne pas r√©sumer, ne pas tronquer, ne pas omettre
            - Ajouter seulement un titre et des points cl√©s
            - Utiliser UN SEUL saut de ligne entre sections
            - √âviter les sauts de ligne multiples
            - Format : **Titre**\n\n**Points cl√©s :**\n‚Ä¢ Point 1\n‚Ä¢ Point 2\n\n**Contenu d√©taill√© :**\n[Contenu original COMPLET]
            
            **EXEMPLE :** Si l'agent a g√©n√©r√© 30 questions, afficher les 30 questions compl√®tes.
            """
            
            result = llm.invoke(prompt)
            return result.content if hasattr(result, 'content') else str(result)
            
        except Exception as e:
            logger.error(f"Erreur lors du formatage avec contexte: {e}")
            return self._format_chatgpt_style_with_context(response, user_question)
    
    def _format_chatgpt_style_with_context(self, response: str, user_question: str) -> str:
        """Formate la r√©ponse en style ChatGPT en tenant compte de la question SANS couper"""
        try:
            # Nettoyer la r√©ponse
            cleaned_response = self._clean_response(response)
            
            # G√©n√©rer un titre contextuel
            title = self._generate_contextual_title(cleaned_response, user_question)
            
            # Pour les documents structur√©s, pr√©server le formatage original
            if any(marker in cleaned_response for marker in ["‚ïê‚ïê‚ïê", "MAINTENANCE", "FORMATION", "DEVIS", "CONTRAT"]):
                # Document structur√© - pr√©server le formatage
                formatted_response = f"**{title}**\n\n{cleaned_response}"
            else:
                # Contenu standard - extraire les points cl√©s
                key_points = self._extract_key_points(cleaned_response)
                formatted_response = f"**{title}**\n\n{key_points}\n\n**Contenu d√©taill√© :**\n{cleaned_response}"
            
            return formatted_response
            
        except Exception as e:
            logger.error(f"Erreur formatage ChatGPT avec contexte: {e}")
            return response
    
    def _generate_contextual_summary(self, response: str, user_question: str) -> str:
        """G√©n√®re un r√©sum√© automatique li√© √† la question"""
        try:
            # Analyser la question pour comprendre le contexte
            question_lower = user_question.lower()
            
            # D√©tecter le type de question
            if any(word in question_lower for word in ['roi', 'retour', 'amortissement', 'rentabilit√©']):
                return "Analyse de rentabilit√© et retour sur investissement de votre installation solaire."
            elif any(word in question_lower for word in ['production', 'kwh', 'kwc', '√©nergie']):
                return "Simulation de production √©nerg√©tique de votre installation photovolta√Øque."
            elif any(word in question_lower for word in ['prix', 'co√ªt', '‚Ç¨', 'devis', 'tarif']):
                return "Estimation des co√ªts et tarifs pour votre projet solaire."
            elif any(word in question_lower for word in ['aide', 'subvention', 'prime', 'financement']):
                return "Informations sur les aides et subventions disponibles."
            elif any(word in question_lower for word in ['installation', 'panneau', 'onduleur', 'technique']):
                return "Conseils techniques pour votre installation photovolta√Øque."
            else:
                # R√©sum√© g√©n√©rique bas√© sur le contenu
                lines = response.split('\n')
                summary_parts = []
                
                for line in lines[:3]:
                    if any(keyword in line.lower() for keyword in ['kwh', 'kwc', '‚Ç¨', 'ans', 'production', 'co√ªt', 'prix']):
                        summary_parts.append(line)
                
                if summary_parts:
                    return summary_parts[0][:100] + "..."
                else:
                    return "Informations sur l'√©nergie solaire en r√©ponse √† votre question."
                
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration r√©sum√© contextuel: {e}")
            return "R√©sum√© de la r√©ponse g√©n√©r√©."
    
    def _generate_contextual_title(self, response: str, user_question: str) -> str:
        """G√©n√®re un titre contextuel bas√© sur la question"""
        try:
            # Analyser la question pour comprendre le contexte
            question_lower = user_question.lower()
            
            # D√©tecter le type de question
            if any(word in question_lower for word in ['roi', 'retour', 'amortissement', 'rentabilit√©']):
                return "Analyse de rentabilit√© de votre installation solaire"
            elif any(word in question_lower for word in ['production', 'kwh', 'kwc', '√©nergie']):
                return "Simulation de production √©nerg√©tique de votre installation photovolta√Øque"
            elif any(word in question_lower for word in ['prix', 'co√ªt', '‚Ç¨', 'devis', 'tarif']):
                return "Estimation des co√ªts et tarifs pour votre projet solaire"
            elif any(word in question_lower for word in ['aide', 'subvention', 'prime', 'financement']):
                return "Informations sur les aides et subventions disponibles"
            elif any(word in question_lower for word in ['installation', 'panneau', 'onduleur', 'technique']):
                return "Conseils techniques pour votre installation photovolta√Øque"
            elif any(word in question_lower for word in ['quiz', 'question', 'test']):
                return "Quiz et questions sur l'√©nergie solaire"
            else:
                return "R√©ponse √† votre question sur l'√©nergie solaire"
                
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration titre contextuel: {e}")
            return "Informations sur l'√©nergie solaire"
    
    def _fallback_summarize_with_context(self, response: str, user_question: str) -> str:
        """Formatage de fallback avec contexte si Gemini √©choue SANS couper"""
        try:
            # Analyser la question pour adapter le titre
            question_lower = user_question.lower()
            
            if 'roi' in question_lower or 'retour' in question_lower:
                title = "Analyse de rentabilit√© de votre installation solaire"
            elif 'production' in question_lower or 'kwh' in question_lower:
                title = "Simulation de production √©nerg√©tique"
            elif 'prix' in question_lower or 'co√ªt' in question_lower:
                title = "Estimation des co√ªts d'installation"
            elif 'quiz' in question_lower or 'question' in question_lower:
                title = "Quiz et questions sur l'√©nergie solaire"
            else:
                title = "R√©ponse √† votre question sur l'√©nergie solaire"
            
            # Extraire les points cl√©s
            key_points = self._extract_key_points(response)
            
            return f"**{title}**\n\n{key_points}\n\n**Contenu d√©taill√© :**\n{response}"
                
        except Exception as e:
            logger.error(f"Erreur fallback avec contexte: {e}")
            return response
    
    def can_handle(self, user_input: str, context: Dict[str, Any] = None) -> float:
        """L'agent r√©sumeur peut traiter toutes les r√©ponses"""
        return 1.0 