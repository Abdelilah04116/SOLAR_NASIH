
import logging
import time
from typing import List, Dict, Any, Optional
import json

logger = logging.getLogger(__name__)

class GeminiProvider:
    """Provider pour Google Gemini 2.0 gratuit"""
    
    def __init__(self, api_key: str, model: str = "gemini-2.0-flash-exp"):
        self.api_key = api_key
        self.model = model
        
        try:
            import google.generativeai as genai
            
            # Configuration de l'API
            genai.configure(api_key=api_key)
            
            # Initialisation du mod√®le
            self.client = genai.GenerativeModel(model)
            
            # Test de connexion
            test_response = self.client.generate_content("Hello")
            if test_response:
                logger.info(f"‚úÖ Gemini provider initialized with model: {model}")
            else:
                raise Exception("Failed to get test response")
                
        except ImportError:
            logger.error("‚ùå Google GenerativeAI library not installed")
            logger.info("üí° Install with: pip install google-generativeai")
            raise
        except Exception as e:
            logger.error(f"‚ùå Gemini initialization failed: {e}")
            raise
    
    def generate_response(self, 
                         prompt: str, 
                         max_tokens: int = 1000, 
                         temperature: float = 0.1) -> str:
        """G√©n√®re une r√©ponse avec Gemini"""
        try:
            # Configuration de g√©n√©ration
            generation_config = {
                'temperature': temperature,
                'top_p': 0.95,
                'top_k': 40,
                'max_output_tokens': max_tokens,
            }
            
            # G√©n√©ration
            response = self.client.generate_content(
                prompt,
                generation_config=generation_config
            )
            
            if response.text:
                return response.text.strip()
            else:
                raise Exception("Empty response from Gemini")
                
        except Exception as e:
            logger.error(f"‚ùå Gemini generation failed: {e}")
            raise
    
    def generate_with_context(self, 
                             query: str, 
                             context: List[Dict[str, Any]],
                             max_tokens: int = 1000,
                             temperature: float = 0.1,
                             system_prompt: Optional[str] = None) -> str:
        """G√©n√®re une r√©ponse avec contexte format√©"""
        try:
            # Formater le prompt avec contexte
            formatted_prompt = self._format_prompt_with_context(query, context, system_prompt)
            
            # G√©n√©rer la r√©ponse
            return self.generate_response(
                prompt=formatted_prompt,
                max_tokens=max_tokens,
                temperature=temperature
            )
            
        except Exception as e:
            logger.error(f"‚ùå Context generation failed: {e}")
            raise
    
    def _format_prompt_with_context(self, 
                                   query: str, 
                                   context: List[Dict[str, Any]], 
                                   system_prompt: Optional[str] = None) -> str:
        """Formate le prompt avec le contexte"""
        
        if not context:
            return query
        
        # Construire le contexte
        context_parts = []
        for i, item in enumerate(context, 1):
            source = item.get('source', 'Source inconnue')
            content = item.get('content', '')
            doc_type = item.get('metadata', {}).get('doc_type', 'texte')
            score = item.get('score', 0.0)
            
            context_parts.append(
                f"üìÑ **Document {i}** ({doc_type.upper()}) - Pertinence: {score:.2f}\n"
                f"**Source:** {source}\n"
                f"**Contenu:** {content}\n"
            )
        
        context_text = "\n".join(context_parts)
        
        # Prompt syst√®me par d√©faut
        default_system = """Tu es un assistant IA expert qui analyse des documents pour r√©pondre aux questions.
        
R√àGLES IMPORTANTES:
- Utilise UNIQUEMENT les informations fournies dans les documents
- Si les documents ne contiennent pas assez d'informations, dis-le clairement
- Cite tes sources en mentionnant le num√©ro du document
- Structure ta r√©ponse de mani√®re claire et logique
- Reste factuel et pr√©cis"""
        
        system_instruction = system_prompt or default_system
        
        # Prompt final
        final_prompt = f"""{system_instruction}

## DOCUMENTS √Ä ANALYSER:

{context_text}

## QUESTION:
{query}

## R√âPONSE:
Bas√© sur l'analyse des documents fournis, voici ma r√©ponse d√©taill√©e:"""
        
        return final_prompt

    def generate(self, prompt, context=None, max_tokens=1000, temperature=0.1, system_prompt=None):
        # Construit le prompt complet avec contexte si besoin
        if context is not None:
            return self.generate_with_context(
                query=prompt,
                context=context,
                max_tokens=max_tokens,
                temperature=temperature,
                system_prompt=system_prompt
            )
        else:
            return self.generate_response(
                prompt=prompt,
                max_tokens=max_tokens,
                temperature=temperature
            )