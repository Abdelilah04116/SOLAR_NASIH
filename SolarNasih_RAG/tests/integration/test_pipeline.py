"""
Tests d'int√©gration pour le pipeline RAG multimodal complet.
Teste l'ensemble du pipeline : ingestion, vectorisation, recherche, g√©n√©ration.
"""

import pytest
import sys
import os
from pathlib import Path
import tempfile
import shutil
import json
import time
from typing import Dict, Any, List, Optional

# Ajout du chemin du projet pour les imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.ingestion.document_loader import DocumentLoader
from src.vectorization.indexer import Indexer
from src.retrieval.search_engine import SearchEngine
from src.generation.response_generator import ResponseGenerator
from src.utils.file_utils import FileUtils

class TestRAGPipeline:
    """Tests d'int√©gration pour le pipeline RAG complet."""
    
    def setup_method(self):
        """Configuration avant chaque test."""
        self.temp_dir = tempfile.mkdtemp(prefix="rag_test_")
        self.test_docs_dir = Path(self.temp_dir) / "test_docs"
        self.test_docs_dir.mkdir(exist_ok=True)
        
        # Cr√©ation de documents de test
        self._create_test_documents()
        
        # Initialisation des composants
        self.document_loader = DocumentLoader()
        self.indexer = Indexer()
        self.search_engine = SearchEngine()
        self.response_generator = ResponseGenerator()
    
    def teardown_method(self):
        """Nettoyage apr√®s chaque test."""
        if self.temp_dir and os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
    
    def _create_test_documents(self):
        """Cr√©e des documents de test pour les tests."""
        # Document texte 1
        doc1_content = """
        L'intelligence artificielle (IA) est un domaine de l'informatique qui vise √† cr√©er des syst√®mes capables d'effectuer des t√¢ches qui n√©cessitent normalement l'intelligence humaine.
        Ces t√¢ches incluent l'apprentissage, le raisonnement, la perception et la r√©solution de probl√®mes.
        L'IA a de nombreuses applications dans des domaines vari√©s comme la m√©decine, la finance, les transports et l'√©ducation.
        """
        
        doc1_path = self.test_docs_dir / "ai_introduction.txt"
        doc1_path.write_text(doc1_content.strip())
        
        # Document texte 2
        doc2_content = """
        Le RAG (Retrieval-Augmented Generation) est une technique qui combine la recherche d'informations et la g√©n√©ration de texte.
        Cette approche permet aux mod√®les de langage d'acc√©der √† des connaissances externes pour am√©liorer leurs r√©ponses.
        Le RAG est particuli√®rement utile pour les t√¢ches qui n√©cessitent des informations √† jour ou sp√©cifiques.
        """
        
        doc2_path = self.test_docs_dir / "rag_explanation.txt"
        doc2_path.write_text(doc2_content.strip())
        
        # Document JSON avec m√©tadonn√©es
        doc3_content = {
            "title": "Machine Learning Basics",
            "content": "Le machine learning est une sous-cat√©gorie de l'IA qui se concentre sur l'apprentissage automatique √† partir de donn√©es.",
            "tags": ["machine learning", "IA", "algorithmes"],
            "author": "Test Author",
            "date": "2024-01-01"
        }
        
        doc3_path = self.test_docs_dir / "ml_basics.json"
        with open(doc3_path, 'w', encoding='utf-8') as f:
            json.dump(doc3_content, f, ensure_ascii=False, indent=2)
    
    def test_full_pipeline_ingestion(self):
        """Test du pipeline complet - √©tape d'ingestion."""
        # Chargement des documents
        documents = self.document_loader.load_documents(str(self.test_docs_dir))
        
        assert len(documents) >= 3, "Au moins 3 documents devraient √™tre charg√©s"
        
        # V√©rification de la structure des documents
        for doc in documents:
            assert "content" in doc, "Chaque document doit avoir un contenu"
            assert "metadata" in doc, "Chaque document doit avoir des m√©tadonn√©es"
            assert "source" in doc, "Chaque document doit avoir une source"
        
        return documents
    
    def test_full_pipeline_indexing(self):
        """Test du pipeline complet - √©tape d'indexation."""
        # Chargement des documents
        documents = self.test_full_pipeline_ingestion()
        
        # Indexation des documents
        start_time = time.time()
        indexing_result = self.indexer.index_documents(documents)
        indexing_time = time.time() - start_time
        
        assert indexing_result["success"], "L'indexation devrait r√©ussir"
        assert indexing_result["documents_indexed"] >= 3, "Au moins 3 documents devraient √™tre index√©s"
        assert indexing_time < 60, "L'indexation ne devrait pas prendre plus de 60 secondes"
        
        return indexing_result
    
    def test_full_pipeline_search(self):
        """Test du pipeline complet - √©tape de recherche."""
        # Indexation pr√©alable
        indexing_result = self.test_full_pipeline_indexing()
        
        # Test de recherche
        query = "intelligence artificielle"
        search_results = self.search_engine.search(query, top_k=3)
        
        assert len(search_results) > 0, "La recherche devrait retourner des r√©sultats"
        assert len(search_results) <= 3, "Le nombre de r√©sultats devrait respecter top_k"
        
        # V√©rification de la structure des r√©sultats
        for result in search_results:
            assert "content" in result, "Chaque r√©sultat doit avoir un contenu"
            assert "score" in result, "Chaque r√©sultat doit avoir un score"
            assert "source" in result, "Chaque r√©sultat doit avoir une source"
            assert 0 <= result["score"] <= 1, "Le score doit √™tre entre 0 et 1"
        
        return search_results
    
    def test_full_pipeline_generation(self):
        """Test du pipeline complet - √©tape de g√©n√©ration."""
        # Recherche pr√©alable
        search_results = self.test_full_pipeline_search()
        
        # G√©n√©ration de r√©ponse
        query = "Qu'est-ce que l'intelligence artificielle ?"
        generation_result = self.response_generator.generate_response(
            query=query,
            retrieved_docs=search_results,
            max_tokens=200,
            temperature=0.1
        )
        
        assert "response" in generation_result, "La g√©n√©ration doit retourner une r√©ponse"
        assert "metadata" in generation_result, "La g√©n√©ration doit retourner des m√©tadonn√©es"
        assert len(generation_result["response"]) > 0, "La r√©ponse ne doit pas √™tre vide"
        
        return generation_result
    
    def test_full_pipeline_end_to_end(self):
        """Test du pipeline complet de bout en bout."""
        # Ex√©cution du pipeline complet
        documents = self.test_full_pipeline_ingestion()
        indexing_result = self.test_full_pipeline_indexing()
        search_results = self.test_full_pipeline_search()
        generation_result = self.test_full_pipeline_generation()
        
        # V√©rifications finales
        assert len(documents) >= 3, "Au moins 3 documents charg√©s"
        assert indexing_result["success"], "Indexation r√©ussie"
        assert len(search_results) > 0, "Recherche avec r√©sultats"
        assert len(generation_result["response"]) > 0, "G√©n√©ration avec r√©ponse"
        
        print(f"‚úÖ Pipeline complet test√© avec succ√®s:")
        print(f"   - Documents charg√©s: {len(documents)}")
        print(f"   - Documents index√©s: {indexing_result['documents_indexed']}")
        print(f"   - R√©sultats de recherche: {len(search_results)}")
        print(f"   - R√©ponse g√©n√©r√©e: {len(generation_result['response'])} caract√®res")
    
    def test_pipeline_with_different_queries(self):
        """Test du pipeline avec diff√©rentes requ√™tes."""
        # Indexation pr√©alable
        self.test_full_pipeline_indexing()
        
        test_queries = [
            "intelligence artificielle",
            "RAG technique",
            "machine learning",
            "g√©n√©ration de texte"
        ]
        
        for query in test_queries:
            # Recherche
            search_results = self.search_engine.search(query, top_k=2)
            assert len(search_results) >= 0, f"Recherche pour '{query}' devrait retourner des r√©sultats"
            
            # G√©n√©ration
            generation_result = self.response_generator.generate_response(
                query=query,
                retrieved_docs=search_results,
                max_tokens=150
            )
            
            assert len(generation_result["response"]) > 0, f"G√©n√©ration pour '{query}' devrait produire une r√©ponse"
    
    def test_pipeline_performance(self):
        """Test de performance du pipeline."""
        # Mesure du temps d'ingestion
        start_time = time.time()
        documents = self.document_loader.load_documents(str(self.test_docs_dir))
        ingestion_time = time.time() - start_time
        
        # Mesure du temps d'indexation
        start_time = time.time()
        indexing_result = self.indexer.index_documents(documents)
        indexing_time = time.time() - start_time
        
        # Mesure du temps de recherche
        start_time = time.time()
        search_results = self.search_engine.search("test query", top_k=5)
        search_time = time.time() - start_time
        
        # Mesure du temps de g√©n√©ration
        start_time = time.time()
        generation_result = self.response_generator.generate_response(
            query="test query",
            retrieved_docs=search_results,
            max_tokens=100
        )
        generation_time = time.time() - start_time
        
        # V√©rifications de performance
        assert ingestion_time < 10, f"Ingestion trop lente: {ingestion_time:.2f}s"
        assert indexing_time < 60, f"Indexation trop lente: {indexing_time:.2f}s"
        assert search_time < 5, f"Recherche trop lente: {search_time:.2f}s"
        assert generation_time < 30, f"G√©n√©ration trop lente: {generation_time:.2f}s"
        
        print(f"üìä Performance du pipeline:")
        print(f"   - Ingestion: {ingestion_time:.2f}s")
        print(f"   - Indexation: {indexing_time:.2f}s")
        print(f"   - Recherche: {search_time:.2f}s")
        print(f"   - G√©n√©ration: {generation_time:.2f}s")
    
    def test_pipeline_error_handling(self):
        """Test de la gestion d'erreurs du pipeline."""
        # Test avec un dossier inexistant
        try:
            documents = self.document_loader.load_documents("/path/that/does/not/exist")
            assert False, "Devrait lever une exception pour un dossier inexistant"
        except Exception:
            pass  # Comportement attendu
        
        # Test avec une requ√™te vide
        try:
            search_results = self.search_engine.search("", top_k=5)
            # Le comportement peut varier selon l'impl√©mentation
        except Exception:
            pass  # Comportement acceptable
        
        # Test avec des documents vides
        empty_docs = []
        try:
            indexing_result = self.indexer.index_documents(empty_docs)
            # Le comportement peut varier selon l'impl√©mentation
        except Exception:
            pass  # Comportement acceptable
    
    def test_pipeline_with_large_documents(self):
        """Test du pipeline avec des documents volumineux."""
        # Cr√©ation d'un document volumineux
        large_content = "Test content. " * 1000  # ~15KB de contenu
        large_doc_path = self.test_docs_dir / "large_document.txt"
        large_doc_path.write_text(large_content)
        
        # Test du pipeline avec le document volumineux
        documents = self.document_loader.load_documents(str(self.test_docs_dir))
        
        # V√©rification que le document volumineux est charg√©
        large_docs = [doc for doc in documents if "large_document.txt" in doc.get("source", "")]
        assert len(large_docs) > 0, "Le document volumineux devrait √™tre charg√©"
        
        # Indexation
        indexing_result = self.indexer.index_documents(documents)
        assert indexing_result["success"], "L'indexation devrait r√©ussir m√™me avec des documents volumineux"
        
        # Recherche
        search_results = self.search_engine.search("test content", top_k=3)
        assert len(search_results) > 0, "La recherche devrait fonctionner avec des documents volumineux"
    
    def test_pipeline_consistency(self):
        """Test de la coh√©rence du pipeline."""
        # Ex√©cution multiple du pipeline
        results = []
        
        for i in range(3):
            # R√©initialisation des composants
            self.indexer = Indexer()
            self.search_engine = SearchEngine()
            
            # Ex√©cution du pipeline
            documents = self.document_loader.load_documents(str(self.test_docs_dir))
            indexing_result = self.indexer.index_documents(documents)
            search_results = self.search_engine.search("intelligence artificielle", top_k=2)
            
            results.append({
                "documents_count": len(documents),
                "indexing_success": indexing_result["success"],
                "search_results_count": len(search_results)
            })
        
        # V√©rification de la coh√©rence
        for i in range(1, len(results)):
            assert results[i]["documents_count"] == results[0]["documents_count"], "Nombre de documents coh√©rent"
            assert results[i]["indexing_success"] == results[0]["indexing_success"], "Succ√®s d'indexation coh√©rent"
            assert results[i]["search_results_count"] == results[0]["search_results_count"], "Nombre de r√©sultats coh√©rent"

def run_pipeline_tests():
    """Fonction pour ex√©cuter tous les tests du pipeline."""
    test_instance = TestRAGPipeline()
    
    # Liste des m√©thodes de test
    test_methods = [
        test_instance.test_full_pipeline_ingestion,
        test_instance.test_full_pipeline_indexing,
        test_instance.test_full_pipeline_search,
        test_instance.test_full_pipeline_generation,
        test_instance.test_full_pipeline_end_to_end,
        test_instance.test_pipeline_with_different_queries,
        test_instance.test_pipeline_performance,
        test_instance.test_pipeline_error_handling,
        test_instance.test_pipeline_with_large_documents,
        test_instance.test_pipeline_consistency
    ]
    
    passed_tests = 0
    failed_tests = 0
    
    print("üöÄ D√©marrage des tests du pipeline RAG...")
    
    for test_method in test_methods:
        try:
            test_method()
            print(f"‚úÖ {test_method.__name__}: PASSED")
            passed_tests += 1
        except Exception as e:
            print(f"‚ùå {test_method.__name__}: FAILED - {str(e)}")
            failed_tests += 1
    
    print(f"\nüìä R√©sultats des tests du pipeline:")
    print(f"Tests r√©ussis: {passed_tests}")
    print(f"Tests √©chou√©s: {failed_tests}")
    print(f"Total: {passed_tests + failed_tests}")
    
    return failed_tests == 0

if __name__ == "__main__":
    success = run_pipeline_tests()
    exit(0 if success else 1)
