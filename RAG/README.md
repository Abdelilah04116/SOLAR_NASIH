# Advanced Multi-Modal Agentic RAG

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![LangChain](https://img.shields.io/badge/LangChain-latest-green.svg)](https://python.langchain.com/)
[![RAG](https://img.shields.io/badge/RAG-Multi--Modal-orange.svg)](https://github.com/langchain-ai/langchain)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

##  Table des Mati√®res
- [Vue d'ensemble](#vue-densemble)
- [Architecture](#architecture)
- [Fonctionnalit√©s](#fonctionnalit√©s)
- [Pr√©requis](#pr√©requis)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Sch√©mas d'Architecture](#sch√©mas-darchitecture)
- [Configuration](#configuration)
- [Contribution](#contribution)
- [Licence](#licence)

##  Vue d'ensemble

Ce projet impl√©mente un syst√®me RAG (Retrieval-Augmented Generation) multi-modal avanc√© avec des capacit√©s d'agent intelligent. Le syst√®me est capable de traiter et d'analyser diff√©rents types de donn√©es (texte, tableaux, images) √† partir de documents PDF et de fournir des r√©ponses contextuelles pr√©cises.

### Caract√©ristiques principales :
- **Multi-modal** : Traitement de texte, tableaux et images
- **Agentic** : Interface utilisateur intelligente avec m√©moire et optimisation
- **RAG Avanc√©** : Recherche vectorielle avec re-ranking et expansion de requ√™tes
- **Pipeline d'ingestion** : Traitement automatique des documents PDF

##  Architecture

Le syst√®me est compos√© de plusieurs composants interconnect√©s :

### Composants principaux :
1. **Agent Interface** : Interface utilisateur intelligente avec m√©moire
2. **Pipeline d'ingestion** : Traitement et indexation des documents
3. **Syst√®me de recherche** : Recherche vectorielle avec optimisation
4. **G√©n√©rateur de r√©ponses** : LLM avec contexte enrichi

##  Fonctionnalit√©s

-  **Traitement PDF** : Extraction automatique de contenu multi-modal
-  **Recherche intelligente** : Recherche vectorielle avec expansion de requ√™tes
-  **Agent conversationnel** : Interface avec m√©moire et contexte
-  **Analyse de tableaux** : Compr√©hension et requ√™te de donn√©es tabulaires
-  **Analyse d'images** : Extraction et recherche de contenu visuel
-  **Re-ranking** : Am√©lioration de la pertinence des r√©sultats

##  Pr√©requis

- Python 3.8+
- GPU recommand√© pour les mod√®les d'embedding
- 8GB+ RAM recommand√©
- Espace disque : 2GB+ pour les mod√®les

### D√©pendances principales :
```
langchain
chromadb
transformers
torch
pypdf
pillow
sentence-transformers
```

##  Installation

1. Clonez le repository :
```bash
git clone https://github.com/votre-username/advanced-multimodal-rag.git
cd advanced-multimodal-rag
```

2. Cr√©ez un environnement virtuel :
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

3. Installez les d√©pendances :
```bash
pip install -r requirements.txt
```

4. Configurez les variables d'environnement :
```bash
cp .env.example .env
# √âditez .env avec vos cl√©s API
```

##  Utilisation

### 1. Ingestion de documents
```python
from src.ingestion import DocumentProcessor

processor = DocumentProcessor()
processor.process_pdf("path/to/document.pdf")
```

### 2. Lancement de l'agent
```python
from src.agent import MultiModalAgent

agent = MultiModalAgent()
response = agent.query("Quelle est la tendance des ventes au Q3 ?")
print(response)
```

### 3. Interface web (optionnel)
```bash
streamlit run app.py
```

##  Sch√©mas d'Architecture

### Architecture Globale
```mermaid
graph TB
    User[üë§ Utilisateur] --> Agent[ü§ñ Agent UI]
    Agent --> Memory[üíæ MEM]
    Agent --> QueryExpansion[üîç Query Expansion]
    
    QueryExpansion --> Compressor[üóúÔ∏è Compressor]
    Compressor --> Reranking[üìä Re-ranking]
    
    Reranking --> Embedding[üîó Embedding Model]
    Embedding --> VectorDB[(üóÉÔ∏è Vector DB)]
    
    VectorDB --> HypotheticalQuestions[‚ùì Hypothetical Questions]
    HypotheticalQuestions --> Retrieval[üì• Structured Retrieval]
    
    Retrieval --> Optimizer[‚ö° Optimizer]
    Optimizer --> LLM[üß† LLM]
    
    PDF[üìÑ PDF] --> Parser[üìù Parser]
    Parser --> Chunker[‚úÇÔ∏è Chunker]
    Chunker --> TextChunks[üìù Text Chunks]
    Chunker --> TableChunks[üìä Table Chunks]
    Chunker --> ImageChunks[üñºÔ∏è Image Chunks]
    
    TextChunks --> Embedding
    TableChunks --> Embedding
    ImageChunks --> Embedding
    
    classDef userClass fill:#e1f5fe
    classDef agentClass fill:#fff3e0
    classDef processClass fill:#f3e5f5
    classDef dataClass fill:#e8f5e8
    classDef storageClass fill:#fce4ec
    
    class User userClass
    class Agent,Memory agentClass
    class QueryExpansion,Compressor,Reranking,Optimizer processClass
    class PDF,TextChunks,TableChunks,ImageChunks dataClass
    class VectorDB,Embedding,LLM storageClass
```

### Pipeline d'Ingestion
```mermaid
flowchart TD
    A[üìÑ Document PDF] --> B[üìù Parser]
    B --> C{Type de Contenu}
    
    C -->|Texte| D[üìù Text Extractor]
    C -->|Tableau| E[üìä Table Extractor]
    C -->|Image| F[üñºÔ∏è Image Extractor]
    
    D --> G[‚úÇÔ∏è Text Chunker]
    E --> H[‚úÇÔ∏è Table Chunker]
    F --> I[‚úÇÔ∏è Image Chunker]
    
    G --> J[üîó Text Embedding]
    H --> K[üîó Table Embedding]
    I --> L[üîó Image Embedding]
    
    J --> M[(üóÉÔ∏è Vector Database)]
    K --> M
    L --> M
    
    M --> N[üìã Metadata Index]
    
    classDef inputClass fill:#e3f2fd
    classDef processClass fill:#fff3e0
    classDef outputClass fill:#e8f5e8
    
    class A inputClass
    class B,C,D,E,F,G,H,I,J,K,L processClass
    class M,N outputClass
```

### Flux de Requ√™te
```mermaid
sequenceDiagram
    participant U as üë§ Utilisateur
    participant A as ü§ñ Agent
    participant M as üíæ M√©moire
    participant Q as üîç Query Processor
    participant V as üóÉÔ∏è Vector DB
    participant L as üß† LLM
    
    U->>A: Requ√™te utilisateur
    A->>M: R√©cup√©ration contexte
    M-->>A: Historique conversation
    
    A->>Q: Expansion de requ√™te
    Q->>Q: G√©n√©ration questions hypoth√©tiques
    Q->>V: Recherche vectorielle
    V-->>Q: Chunks pertinents
    
    Q->>Q: Re-ranking des r√©sultats
    Q-->>A: Contexte optimis√©
    
    A->>L: Prompt + Contexte
    L-->>A: R√©ponse g√©n√©r√©e
    
    A->>M: Mise √† jour m√©moire
    A-->>U: R√©ponse finale
```

### Architecture des Composants
```mermaid
graph LR
    subgraph "üîß Ingestion Pipeline"
        P[Parser] --> C[Chunker]
        C --> E[Embedder]
        E --> D[(Database)]
    end
    
    subgraph "ü§ñ Agent System"
        UI[Agent UI] --> MEM[Memory]
        UI --> QE[Query Expansion]
    end
    
    subgraph "üîç Retrieval System"
        QE --> COMP[Compressor]
        COMP --> RR[Re-ranker]
        RR --> SR[Structured Retrieval]
    end
    
    subgraph "‚ö° Generation System"
        SR --> OPT[Optimizer]
        OPT --> LLM[Large Language Model]
    end
    
    D --> SR
    LLM --> UI
    
    classDef ingestionClass fill:#e8f5e8
    classDef agentClass fill:#fff3e0
    classDef retrievalClass fill:#f3e5f5
    classDef generationClass fill:#fce4ec
    
    class P,C,E,D ingestionClass
    class UI,MEM,QE agentClass
    class COMP,RR,SR retrievalClass
    class OPT,LLM generationClass
```

##  Configuration

### Mod√®les d'Embedding
```python
# Configuration dans config.py
EMBEDDING_MODEL = "sentence-transformers/all-mpnet-base-v2"
EMBEDDING_DIMENSION = 768
```

### Base de donn√©es vectorielle
```python
# Configuration ChromaDB
CHROMA_DB_PATH = "./data/chroma_db"
COLLECTION_NAME = "multimodal_documents"
```

### Mod√®le LLM
```python
# Configuration du mod√®le de g√©n√©ration
LLM_MODEL = "gpt-4" # ou votre mod√®le pr√©f√©r√©
MAX_TOKENS = 4096
TEMPERATURE = 0.1
```

##  Workflow Type

1. **Ingestion** : Upload et traitement des documents PDF
2. **Indexation** : Cr√©ation des embeddings et stockage vectoriel
3. **Requ√™te** : Saisie de la question par l'utilisateur
4. **Expansion** : G√©n√©ration de questions hypoth√©tiques
5. **Recherche** : R√©cup√©ration des chunks pertinents
6. **Re-ranking** : Optimisation de la pertinence
7. **G√©n√©ration** : Cr√©ation de la r√©ponse finale
8. **M√©morisation** : Stockage du contexte conversationnel

##  Contribution

1. Forkez le projet
2. Cr√©ez une branche pour votre fonctionnalit√© (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Pushez vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

##  Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

##  Roadmap

- [ ] Support des documents Word et PowerPoint
- [ ] Int√©gration d'APIs externes
- [ ] Interface web am√©lior√©e
- [ ] Support multilingue
- [ ] Optimisation des performances
- [ ] Tests unitaires complets

##  Support

Pour toute question ou probl√®me, n'h√©sitez pas √† Contacter :
- abdelilahourti@gmail.com

---

**Note** : Ce projet est en d√©veloppement actif. Les fonctionnalit√©s peuvent √©voluer.